<!DOCTYPE html> <html lang="en"> <head> <meta name="google-site-verification" content="google9aedf817252bb42b"/> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publication | Kwan-Yee Lin</title> <meta name="author" content="Kwan-Yee Lin"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/milky-way.png"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://kwanyeelin.github.io/publication/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://kwanyeelin.github.io/">Kwan-Yee Lin</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publication/">Publication<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/project/">Industry</a> </li> <li class="nav-item "> <a class="nav-link" href="/dataset/">Dataset</a> </li> <li class="nav-item "> <a class="nav-link" href="/software/">Software</a> </li> <li class="nav-item "> <a class="nav-link" href="/Others/">Others</a> </li> <div class="toggle-container"> <a id="light-toggle"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </a> </div> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publication</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="year">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4"> <figure> <div class="video-container"> <video class="img-fluid z-dept-1 rounded" autoplay="" loop="" muted="" poster="/assets/img/publication/kwanyee2025legoh.png" preload="metadata" playsinline="" webkit-playsinline="" onmouseover="this.controls=true" onmouseout="this.controls=false"><source src="/assets/videos/kwanyee2025legoh.mp4" type="video/mp4"></source><p>Your browser does not support the video tag. <a href="/assets/videos/kwanyee2025legoh.mp4">Download the video</a> instead.</p> </video> </div> </figure> <style>.video-container{position:relative;width:100%;height:0;padding-bottom:56.25%;background-color:#f8f9fa;border-radius:8px;overflow:hidden}.video-container video{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:8px;background-color:#000}.video-container video::-webkit-media-controls{background-color:rgba(0,0,0,0.5)}.video-container video::-webkit-media-controls-panel{background-color:transparent}.video-container video::-webkit-media-controls-play-button{background-color:transparent}.video-container video::-webkit-media-controls-timeline{background-color:transparent}.video-container video{background-color:#000!important;background-image:none!important;object-fit:cover;-webkit-appearance:none;appearance:none}.video-container video::-webkit-media-controls{background-color:transparent!important}.video-container video::-webkit-media-controls-panel{background-color:transparent!important}.video-container video::-webkit-media-controls-overlay-play-button{background-color:transparent!important}.video-container video::-webkit-media-controls-start-playback-button{background-color:transparent!important}.video-container video::-webkit-media-controls-enclosure{background-color:transparent!important}.video-container video::-webkit-media-controls-fullscreen-button{background-color:transparent!important}.video-container video::-webkit-media-controls-timeline{background-color:transparent!important}.video-container video::-webkit-media-controls-volume-slider{background-color:transparent!important}.video-container video::-webkit-media-controls-mute-button{background-color:transparent!important}.video-container video[poster]{background-color:#000!important;background-image:none!important}.video-container video::-webkit-media-controls-container{background-color:transparent!important}</style> <script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll(".video-container video").forEach(function(e){e.style.backgroundColor="#000",e.style.backgroundImage="none",e.style.webkitAppearance="none",e.style.appearance="none",e.poster&&(e.style.backgroundImage="url("+e.poster+")",e.style.backgroundSize="cover",e.style.backgroundPosition="center");["loadstart","loadedmetadata","loadeddata","canplay","canplaythrough","progress"].forEach(function(t){e.addEventListener(t,function(){this.style.backgroundColor="#000",this.style.backgroundImage=this.poster?"url("+this.poster+")":"none"})}),e.addEventListener("click",function(){this.style.backgroundColor="#000"}),e.addEventListener("mouseenter",function(){this.style.backgroundColor="#000"});new MutationObserver(function(t){t.forEach(function(t){"attributes"===t.type&&"style"===t.attributeName&&(e.style.backgroundColor="#000",e.style.backgroundImage=e.poster?"url("+e.poster+")":"none")})}).observe(e,{attributes:!0,attributeFilter:["style"]})})});</script> </div> <div id="kwanyee2025legoh" class="col-sm-8"> <div class="title">Let Humanoid Robots Go Hiking! Integrative Skill Development over Complex Trails</div> <div class="author"> <em>Kwan-Yee Lin</em>, and Stella X. Yu </div> <div class="periodical"> <em>Computer Vision and Pattern Recognition (CVPR),</em> 2025 </div> <div class="links"> <a href="https://lego-h-humanoidrobothiking.github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/publication/fan2025embodiedhuman-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/publication/fan2025embodiedhuman-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/publication/fan2025embodiedhuman-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/publication/fan2025embodiedhuman.png"> </picture> </figure> </div> <div id="fan2025embodiedhuman" class="col-sm-8"> <div class="title">Who and Where Am I? Embodied Cognition-Aware Virtual Humans</div> <div class="author"> </div> <div class="periodical"> <em>Technical report, coming soon,</em> 2025 </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="year">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/publication/dongwei2024timewalker-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/publication/dongwei2024timewalker-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/publication/dongwei2024timewalker-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/publication/dongwei2024timewalker.png"> </picture> </figure> </div> <div id="dongwei2024timewalker" class="col-sm-8"> <div class="title">TimeWalker: Personalized Neural Space for Lifelong Head Avatars</div> <div class="author">Dongwei Pan, Yang Li, Hongsheng Li, and <em>Kwan-Yee Lin</em> </div> <div class="periodical"> <em>Technical report, arXiv:2412.02421,</em> 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2404.06780" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://www.youtube.com/watch?v=x8cpOVMY_ko" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">YouTube</a> <a href="https://timewalker2024.github.io/timewalker.github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/publication/fan2024urbanarchitect-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/publication/fan2024urbanarchitect-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/publication/fan2024urbanarchitect-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/publication/fan2024urbanarchitect.png"> </picture> </figure> </div> <div id="fan2024urbanarchitect" class="col-sm-8"> <div class="title">Urban Architect: Steerable 3D Urban Scene Generation with Layout Prior</div> <div class="author">Fan Lu,  <em>Kwan-Yee Lin</em> †, Yan Xu, Hongsheng Li, Guang Chen, and Changjun Jiang </div> <div class="periodical"> <em>Technical report, arXiv:2404.06780,</em> 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2404.06780" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://www.youtube.com/watch?v=CEPquApsPjI" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">YouTube</a> <a href="https://urbanarchitect.github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/publication/baixin2024parameterization-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/publication/baixin2024parameterization-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/publication/baixin2024parameterization-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/publication/baixin2024parameterization.png"> </picture> </figure> </div> <div id="baixin2024parameterization" class="col-sm-8"> <div class="title">Parameterization-driven Neural Surface Reconstruction for Object-oriented Editing in Neural Rendering</div> <div class="author">Baixin Xu, Jiangbei Hu, Fei Hou,  <em>Kwan-Yee Lin</em>, Wayne Wu, Chen Qian, and Ying He </div> <div class="periodical"> <em>European Conference on Computer Vision (ECCV),</em> 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2310.05524" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://xubaixinxbx.github.io/neuparam/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <div class="video-container"> <video class="img-fluid z-dept-1 rounded" autoplay="" loop="" muted="" poster="/assets/img/publication/shikai2024cosmicman.png" preload="metadata" playsinline="" webkit-playsinline="" onmouseover="this.controls=true" onmouseout="this.controls=false"><source src="/assets/videos/shikai2024cosmicman.mp4" type="video/mp4"></source><p>Your browser does not support the video tag. <a href="/assets/videos/shikai2024cosmicman.mp4">Download the video</a> instead.</p> </video> </div> </figure> <style>.video-container{position:relative;width:100%;height:0;padding-bottom:56.25%;background-color:#f8f9fa;border-radius:8px;overflow:hidden}.video-container video{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:8px;background-color:#000}.video-container video::-webkit-media-controls{background-color:rgba(0,0,0,0.5)}.video-container video::-webkit-media-controls-panel{background-color:transparent}.video-container video::-webkit-media-controls-play-button{background-color:transparent}.video-container video::-webkit-media-controls-timeline{background-color:transparent}.video-container video{background-color:#000!important;background-image:none!important;object-fit:cover;-webkit-appearance:none;appearance:none}.video-container video::-webkit-media-controls{background-color:transparent!important}.video-container video::-webkit-media-controls-panel{background-color:transparent!important}.video-container video::-webkit-media-controls-overlay-play-button{background-color:transparent!important}.video-container video::-webkit-media-controls-start-playback-button{background-color:transparent!important}.video-container video::-webkit-media-controls-enclosure{background-color:transparent!important}.video-container video::-webkit-media-controls-fullscreen-button{background-color:transparent!important}.video-container video::-webkit-media-controls-timeline{background-color:transparent!important}.video-container video::-webkit-media-controls-volume-slider{background-color:transparent!important}.video-container video::-webkit-media-controls-mute-button{background-color:transparent!important}.video-container video[poster]{background-color:#000!important;background-image:none!important}.video-container video::-webkit-media-controls-container{background-color:transparent!important}</style> <script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll(".video-container video").forEach(function(e){e.style.backgroundColor="#000",e.style.backgroundImage="none",e.style.webkitAppearance="none",e.style.appearance="none",e.poster&&(e.style.backgroundImage="url("+e.poster+")",e.style.backgroundSize="cover",e.style.backgroundPosition="center");["loadstart","loadedmetadata","loadeddata","canplay","canplaythrough","progress"].forEach(function(t){e.addEventListener(t,function(){this.style.backgroundColor="#000",this.style.backgroundImage=this.poster?"url("+this.poster+")":"none"})}),e.addEventListener("click",function(){this.style.backgroundColor="#000"}),e.addEventListener("mouseenter",function(){this.style.backgroundColor="#000"});new MutationObserver(function(t){t.forEach(function(t){"attributes"===t.type&&"style"===t.attributeName&&(e.style.backgroundColor="#000",e.style.backgroundImage=e.poster?"url("+e.poster+")":"none")})}).observe(e,{attributes:!0,attributeFilter:["style"]})})});</script> </div> <div id="shikai2024cosmicman" class="col-sm-8"> <div class="title">CosmicMan: A Text-to-Image Foundation Model for Humans</div> <div class="author">Shikai Li, Jianglin Fu, Kaiyuan Liu, Wentao Wang,  <em>Kwan-Yee Lin</em> †, and Wayne Wu </div> <div class="periodical"> <em>Computer Vision and Pattern Recognition (CVPR),</em> 2024 </div> <div class="links"> <a href="https://www.youtube.com/watch?v=fk2fniU6oyM" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">YouTube</a> <a href="https://cosmicman-cvpr2024.github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> <div class="highlight-label" style="margin-top: 8px; text-align: left;"> <strong style="color: red; font-size: 1.1em;">Highlight</strong> </div> </div> </div> </li> </ol> <h2 class="year">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4"> <figure> <div class="video-container"> <video class="img-fluid z-dept-1 rounded" autoplay="" loop="" muted="" poster="/assets/img/publication/contributors2023renderme360.png" preload="metadata" playsinline="" webkit-playsinline="" onmouseover="this.controls=true" onmouseout="this.controls=false"><source src="/assets/videos/contributors2023renderme360.mp4" type="video/mp4"></source><p>Your browser does not support the video tag. <a href="/assets/videos/contributors2023renderme360.mp4">Download the video</a> instead.</p> </video> </div> </figure> <style>.video-container{position:relative;width:100%;height:0;padding-bottom:56.25%;background-color:#f8f9fa;border-radius:8px;overflow:hidden}.video-container video{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:8px;background-color:#000}.video-container video::-webkit-media-controls{background-color:rgba(0,0,0,0.5)}.video-container video::-webkit-media-controls-panel{background-color:transparent}.video-container video::-webkit-media-controls-play-button{background-color:transparent}.video-container video::-webkit-media-controls-timeline{background-color:transparent}.video-container video{background-color:#000!important;background-image:none!important;object-fit:cover;-webkit-appearance:none;appearance:none}.video-container video::-webkit-media-controls{background-color:transparent!important}.video-container video::-webkit-media-controls-panel{background-color:transparent!important}.video-container video::-webkit-media-controls-overlay-play-button{background-color:transparent!important}.video-container video::-webkit-media-controls-start-playback-button{background-color:transparent!important}.video-container video::-webkit-media-controls-enclosure{background-color:transparent!important}.video-container video::-webkit-media-controls-fullscreen-button{background-color:transparent!important}.video-container video::-webkit-media-controls-timeline{background-color:transparent!important}.video-container video::-webkit-media-controls-volume-slider{background-color:transparent!important}.video-container video::-webkit-media-controls-mute-button{background-color:transparent!important}.video-container video[poster]{background-color:#000!important;background-image:none!important}.video-container video::-webkit-media-controls-container{background-color:transparent!important}</style> <script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll(".video-container video").forEach(function(e){e.style.backgroundColor="#000",e.style.backgroundImage="none",e.style.webkitAppearance="none",e.style.appearance="none",e.poster&&(e.style.backgroundImage="url("+e.poster+")",e.style.backgroundSize="cover",e.style.backgroundPosition="center");["loadstart","loadedmetadata","loadeddata","canplay","canplaythrough","progress"].forEach(function(t){e.addEventListener(t,function(){this.style.backgroundColor="#000",this.style.backgroundImage=this.poster?"url("+this.poster+")":"none"})}),e.addEventListener("click",function(){this.style.backgroundColor="#000"}),e.addEventListener("mouseenter",function(){this.style.backgroundColor="#000"});new MutationObserver(function(t){t.forEach(function(t){"attributes"===t.type&&"style"===t.attributeName&&(e.style.backgroundColor="#000",e.style.backgroundImage=e.poster?"url("+e.poster+")":"none")})}).observe(e,{attributes:!0,attributeFilter:["style"]})})});</script> </div> <div id="contributors2023renderme360" class="col-sm-8"> <div class="title">RenderMe-360: A Large Digital Asset Library and Benchmarks Towards High-fidelity Head Avatars</div> <div class="author">Dongwei Pan,  etal., and <em>Kwan-Yee Lin</em> </div> <div class="periodical"> <em>Neural Information Processing Systems (NeurIPS), Datasets and Benchmarks,</em> 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2305.13353" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://www.youtube.com/watch?v=nIgrtQwkrdg" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">YouTube</a> <a href="https://renderme-360.github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <div class="video-container"> <video class="img-fluid z-dept-1 rounded" autoplay="" loop="" muted="" poster="/assets/img/publication/contributors2023dnarendering.png" preload="metadata" playsinline="" webkit-playsinline="" onmouseover="this.controls=true" onmouseout="this.controls=false"><source src="/assets/videos/contributors2023dnarendering.mp4" type="video/mp4"></source><p>Your browser does not support the video tag. <a href="/assets/videos/contributors2023dnarendering.mp4">Download the video</a> instead.</p> </video> </div> </figure> <style>.video-container{position:relative;width:100%;height:0;padding-bottom:56.25%;background-color:#f8f9fa;border-radius:8px;overflow:hidden}.video-container video{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:8px;background-color:#000}.video-container video::-webkit-media-controls{background-color:rgba(0,0,0,0.5)}.video-container video::-webkit-media-controls-panel{background-color:transparent}.video-container video::-webkit-media-controls-play-button{background-color:transparent}.video-container video::-webkit-media-controls-timeline{background-color:transparent}.video-container video{background-color:#000!important;background-image:none!important;object-fit:cover;-webkit-appearance:none;appearance:none}.video-container video::-webkit-media-controls{background-color:transparent!important}.video-container video::-webkit-media-controls-panel{background-color:transparent!important}.video-container video::-webkit-media-controls-overlay-play-button{background-color:transparent!important}.video-container video::-webkit-media-controls-start-playback-button{background-color:transparent!important}.video-container video::-webkit-media-controls-enclosure{background-color:transparent!important}.video-container video::-webkit-media-controls-fullscreen-button{background-color:transparent!important}.video-container video::-webkit-media-controls-timeline{background-color:transparent!important}.video-container video::-webkit-media-controls-volume-slider{background-color:transparent!important}.video-container video::-webkit-media-controls-mute-button{background-color:transparent!important}.video-container video[poster]{background-color:#000!important;background-image:none!important}.video-container video::-webkit-media-controls-container{background-color:transparent!important}</style> <script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll(".video-container video").forEach(function(e){e.style.backgroundColor="#000",e.style.backgroundImage="none",e.style.webkitAppearance="none",e.style.appearance="none",e.poster&&(e.style.backgroundImage="url("+e.poster+")",e.style.backgroundSize="cover",e.style.backgroundPosition="center");["loadstart","loadedmetadata","loadeddata","canplay","canplaythrough","progress"].forEach(function(t){e.addEventListener(t,function(){this.style.backgroundColor="#000",this.style.backgroundImage=this.poster?"url("+this.poster+")":"none"})}),e.addEventListener("click",function(){this.style.backgroundColor="#000"}),e.addEventListener("mouseenter",function(){this.style.backgroundColor="#000"});new MutationObserver(function(t){t.forEach(function(t){"attributes"===t.type&&"style"===t.attributeName&&(e.style.backgroundColor="#000",e.style.backgroundImage=e.poster?"url("+e.poster+")":"none")})}).observe(e,{attributes:!0,attributeFilter:["style"]})})});</script> </div> <div id="contributors2023dnarendering" class="col-sm-8"> <div class="title">DNA-Rendering: A Diverse Neural Actor Repository for High-Fidelity Human-centric Rendering</div> <div class="author">Wei Cheng,  etal., and <em>Kwan-Yee Lin</em> </div> <div class="periodical"> <em>International Conference on Computer Vision (ICCV),</em> 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2307.10173" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://www.youtube.com/watch?v=xlhfvxvu7nc" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">YouTube</a> <a href="https://dna-rendering.github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <div class="video-container"> <video class="img-fluid z-dept-1 rounded" autoplay="" loop="" muted="" poster="/assets/img/publication/jianglin2023unitedhuman.png" preload="metadata" playsinline="" webkit-playsinline="" onmouseover="this.controls=true" onmouseout="this.controls=false"><source src="/assets/videos/jianglin2023unitedhuman.mp4" type="video/mp4"></source><p>Your browser does not support the video tag. <a href="/assets/videos/jianglin2023unitedhuman.mp4">Download the video</a> instead.</p> </video> </div> </figure> <style>.video-container{position:relative;width:100%;height:0;padding-bottom:56.25%;background-color:#f8f9fa;border-radius:8px;overflow:hidden}.video-container video{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:8px;background-color:#000}.video-container video::-webkit-media-controls{background-color:rgba(0,0,0,0.5)}.video-container video::-webkit-media-controls-panel{background-color:transparent}.video-container video::-webkit-media-controls-play-button{background-color:transparent}.video-container video::-webkit-media-controls-timeline{background-color:transparent}.video-container video{background-color:#000!important;background-image:none!important;object-fit:cover;-webkit-appearance:none;appearance:none}.video-container video::-webkit-media-controls{background-color:transparent!important}.video-container video::-webkit-media-controls-panel{background-color:transparent!important}.video-container video::-webkit-media-controls-overlay-play-button{background-color:transparent!important}.video-container video::-webkit-media-controls-start-playback-button{background-color:transparent!important}.video-container video::-webkit-media-controls-enclosure{background-color:transparent!important}.video-container video::-webkit-media-controls-fullscreen-button{background-color:transparent!important}.video-container video::-webkit-media-controls-timeline{background-color:transparent!important}.video-container video::-webkit-media-controls-volume-slider{background-color:transparent!important}.video-container video::-webkit-media-controls-mute-button{background-color:transparent!important}.video-container video[poster]{background-color:#000!important;background-image:none!important}.video-container video::-webkit-media-controls-container{background-color:transparent!important}</style> <script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll(".video-container video").forEach(function(e){e.style.backgroundColor="#000",e.style.backgroundImage="none",e.style.webkitAppearance="none",e.style.appearance="none",e.poster&&(e.style.backgroundImage="url("+e.poster+")",e.style.backgroundSize="cover",e.style.backgroundPosition="center");["loadstart","loadedmetadata","loadeddata","canplay","canplaythrough","progress"].forEach(function(t){e.addEventListener(t,function(){this.style.backgroundColor="#000",this.style.backgroundImage=this.poster?"url("+this.poster+")":"none"})}),e.addEventListener("click",function(){this.style.backgroundColor="#000"}),e.addEventListener("mouseenter",function(){this.style.backgroundColor="#000"});new MutationObserver(function(t){t.forEach(function(t){"attributes"===t.type&&"style"===t.attributeName&&(e.style.backgroundColor="#000",e.style.backgroundImage=e.poster?"url("+e.poster+")":"none")})}).observe(e,{attributes:!0,attributeFilter:["style"]})})});</script> </div> <div id="jianglin2023unitedhuman" class="col-sm-8"> <div class="title">UnitedHuman: Harnessing Multi-Source Data for High-Resolution Human Generation</div> <div class="author">Jianglin Fu, Shikai Li, Yuming Jiang,  <em>Kwan-Yee Lin</em> †, Ziwei Liu, and Wayne Wu </div> <div class="periodical"> <em>International Conference on Computer Vision (ICCV),</em> 2023 </div> <div class="links"> <a href="https://www.youtube.com/watch?v=pdsfUYFDLSw" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">YouTube</a> <a href="https://unitedhuman.github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <div class="video-container"> <video class="img-fluid z-dept-1 rounded" autoplay="" loop="" muted="" poster="/assets/img/publication/fan2023urban.png" preload="metadata" playsinline="" webkit-playsinline="" onmouseover="this.controls=true" onmouseout="this.controls=false"><source src="/assets/videos/fan2023urban.mp4" type="video/mp4"></source><p>Your browser does not support the video tag. <a href="/assets/videos/fan2023urban.mp4">Download the video</a> instead.</p> </video> </div> </figure> <style>.video-container{position:relative;width:100%;height:0;padding-bottom:56.25%;background-color:#f8f9fa;border-radius:8px;overflow:hidden}.video-container video{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:8px;background-color:#000}.video-container video::-webkit-media-controls{background-color:rgba(0,0,0,0.5)}.video-container video::-webkit-media-controls-panel{background-color:transparent}.video-container video::-webkit-media-controls-play-button{background-color:transparent}.video-container video::-webkit-media-controls-timeline{background-color:transparent}.video-container video{background-color:#000!important;background-image:none!important;object-fit:cover;-webkit-appearance:none;appearance:none}.video-container video::-webkit-media-controls{background-color:transparent!important}.video-container video::-webkit-media-controls-panel{background-color:transparent!important}.video-container video::-webkit-media-controls-overlay-play-button{background-color:transparent!important}.video-container video::-webkit-media-controls-start-playback-button{background-color:transparent!important}.video-container video::-webkit-media-controls-enclosure{background-color:transparent!important}.video-container video::-webkit-media-controls-fullscreen-button{background-color:transparent!important}.video-container video::-webkit-media-controls-timeline{background-color:transparent!important}.video-container video::-webkit-media-controls-volume-slider{background-color:transparent!important}.video-container video::-webkit-media-controls-mute-button{background-color:transparent!important}.video-container video[poster]{background-color:#000!important;background-image:none!important}.video-container video::-webkit-media-controls-container{background-color:transparent!important}</style> <script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll(".video-container video").forEach(function(e){e.style.backgroundColor="#000",e.style.backgroundImage="none",e.style.webkitAppearance="none",e.style.appearance="none",e.poster&&(e.style.backgroundImage="url("+e.poster+")",e.style.backgroundSize="cover",e.style.backgroundPosition="center");["loadstart","loadedmetadata","loadeddata","canplay","canplaythrough","progress"].forEach(function(t){e.addEventListener(t,function(){this.style.backgroundColor="#000",this.style.backgroundImage=this.poster?"url("+this.poster+")":"none"})}),e.addEventListener("click",function(){this.style.backgroundColor="#000"}),e.addEventListener("mouseenter",function(){this.style.backgroundColor="#000"});new MutationObserver(function(t){t.forEach(function(t){"attributes"===t.type&&"style"===t.attributeName&&(e.style.backgroundColor="#000",e.style.backgroundImage=e.poster?"url("+e.poster+")":"none")})}).observe(e,{attributes:!0,attributeFilter:["style"]})})});</script> </div> <div id="fan2023urban" class="col-sm-8"> <div class="title">Urban Radiance Field Representation with Deformable Neural Mesh Primitives</div> <div class="author">Fan Lu, Yan Xu, Guang Chen, Hongsheng Li,  <em>Kwan-Yee Lin</em> †, and Changjun Jiang </div> <div class="periodical"> <em>International Conference on Computer Vision (ICCV),</em> 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2307.10776" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://www.youtube.com/watch?v=JABhlaVq4VA" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">YouTube</a> <a href="https://dnmp.github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <div class="video-container"> <video class="img-fluid z-dept-1 rounded" autoplay="" loop="" muted="" poster="/assets/img/publication/slrsmf2022.png" preload="metadata" playsinline="" webkit-playsinline="" onmouseover="this.controls=true" onmouseout="this.controls=false"><source src="/assets/videos/slrsmf2022.mp4" type="video/mp4"></source><p>Your browser does not support the video tag. <a href="/assets/videos/slrsmf2022.mp4">Download the video</a> instead.</p> </video> </div> </figure> <style>.video-container{position:relative;width:100%;height:0;padding-bottom:56.25%;background-color:#f8f9fa;border-radius:8px;overflow:hidden}.video-container video{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:8px;background-color:#000}.video-container video::-webkit-media-controls{background-color:rgba(0,0,0,0.5)}.video-container video::-webkit-media-controls-panel{background-color:transparent}.video-container video::-webkit-media-controls-play-button{background-color:transparent}.video-container video::-webkit-media-controls-timeline{background-color:transparent}.video-container video{background-color:#000!important;background-image:none!important;object-fit:cover;-webkit-appearance:none;appearance:none}.video-container video::-webkit-media-controls{background-color:transparent!important}.video-container video::-webkit-media-controls-panel{background-color:transparent!important}.video-container video::-webkit-media-controls-overlay-play-button{background-color:transparent!important}.video-container video::-webkit-media-controls-start-playback-button{background-color:transparent!important}.video-container video::-webkit-media-controls-enclosure{background-color:transparent!important}.video-container video::-webkit-media-controls-fullscreen-button{background-color:transparent!important}.video-container video::-webkit-media-controls-timeline{background-color:transparent!important}.video-container video::-webkit-media-controls-volume-slider{background-color:transparent!important}.video-container video::-webkit-media-controls-mute-button{background-color:transparent!important}.video-container video[poster]{background-color:#000!important;background-image:none!important}.video-container video::-webkit-media-controls-container{background-color:transparent!important}</style> <script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll(".video-container video").forEach(function(e){e.style.backgroundColor="#000",e.style.backgroundImage="none",e.style.webkitAppearance="none",e.style.appearance="none",e.poster&&(e.style.backgroundImage="url("+e.poster+")",e.style.backgroundSize="cover",e.style.backgroundPosition="center");["loadstart","loadedmetadata","loadeddata","canplay","canplaythrough","progress"].forEach(function(t){e.addEventListener(t,function(){this.style.backgroundColor="#000",this.style.backgroundImage=this.poster?"url("+this.poster+")":"none"})}),e.addEventListener("click",function(){this.style.backgroundColor="#000"}),e.addEventListener("mouseenter",function(){this.style.backgroundColor="#000"});new MutationObserver(function(t){t.forEach(function(t){"attributes"===t.type&&"style"===t.attributeName&&(e.style.backgroundColor="#000",e.style.backgroundImage=e.poster?"url("+e.poster+")":"none")})}).observe(e,{attributes:!0,attributeFilter:["style"]})})});</script> </div> <div id="slrsmf2022" class="col-sm-8"> <div class="title">Simulating Fluids in Real-World Still Images</div> <div class="author">Siming Fan, Jingtan Piao, Chen Qian, Hongsheng Li, and <em>Kwan-Yee Lin</em> </div> <div class="periodical"> <em>International Conference on Computer Vision (ICCV),</em> 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2204.11335" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://www.youtube.com/watch?v=Aatrl16t-V8" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">YouTube</a> <a href="https://slr-sfs.github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> <div class="oral-label" style="margin-top: 8px; text-align: left;"> <strong style="color: red; font-size: 1.1em;">Oral</strong> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <div class="video-container"> <video class="img-fluid z-dept-1 rounded" autoplay="" loop="" muted="" poster="/assets/img/publication/zhengming2023monohuman.png" preload="metadata" playsinline="" webkit-playsinline="" onmouseover="this.controls=true" onmouseout="this.controls=false"><source src="/assets/videos/zhengming2023monohuman.mp4" type="video/mp4"></source><p>Your browser does not support the video tag. <a href="/assets/videos/zhengming2023monohuman.mp4">Download the video</a> instead.</p> </video> </div> </figure> <style>.video-container{position:relative;width:100%;height:0;padding-bottom:56.25%;background-color:#f8f9fa;border-radius:8px;overflow:hidden}.video-container video{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:8px;background-color:#000}.video-container video::-webkit-media-controls{background-color:rgba(0,0,0,0.5)}.video-container video::-webkit-media-controls-panel{background-color:transparent}.video-container video::-webkit-media-controls-play-button{background-color:transparent}.video-container video::-webkit-media-controls-timeline{background-color:transparent}.video-container video{background-color:#000!important;background-image:none!important;object-fit:cover;-webkit-appearance:none;appearance:none}.video-container video::-webkit-media-controls{background-color:transparent!important}.video-container video::-webkit-media-controls-panel{background-color:transparent!important}.video-container video::-webkit-media-controls-overlay-play-button{background-color:transparent!important}.video-container video::-webkit-media-controls-start-playback-button{background-color:transparent!important}.video-container video::-webkit-media-controls-enclosure{background-color:transparent!important}.video-container video::-webkit-media-controls-fullscreen-button{background-color:transparent!important}.video-container video::-webkit-media-controls-timeline{background-color:transparent!important}.video-container video::-webkit-media-controls-volume-slider{background-color:transparent!important}.video-container video::-webkit-media-controls-mute-button{background-color:transparent!important}.video-container video[poster]{background-color:#000!important;background-image:none!important}.video-container video::-webkit-media-controls-container{background-color:transparent!important}</style> <script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll(".video-container video").forEach(function(e){e.style.backgroundColor="#000",e.style.backgroundImage="none",e.style.webkitAppearance="none",e.style.appearance="none",e.poster&&(e.style.backgroundImage="url("+e.poster+")",e.style.backgroundSize="cover",e.style.backgroundPosition="center");["loadstart","loadedmetadata","loadeddata","canplay","canplaythrough","progress"].forEach(function(t){e.addEventListener(t,function(){this.style.backgroundColor="#000",this.style.backgroundImage=this.poster?"url("+this.poster+")":"none"})}),e.addEventListener("click",function(){this.style.backgroundColor="#000"}),e.addEventListener("mouseenter",function(){this.style.backgroundColor="#000"});new MutationObserver(function(t){t.forEach(function(t){"attributes"===t.type&&"style"===t.attributeName&&(e.style.backgroundColor="#000",e.style.backgroundImage=e.poster?"url("+e.poster+")":"none")})}).observe(e,{attributes:!0,attributeFilter:["style"]})})});</script> </div> <div id="zhengming2023monohuman" class="col-sm-8"> <div class="title">MonoHuman: Animatable Human Neural Field from Monocular Video</div> <div class="author">Zhengming Yu, Wei Cheng, Xian Liu, Wayne Wu, and <em>Kwan-Yee Lin</em> </div> <div class="periodical"> <em>Conference on Computer Vision and Pattern Recognition (CVPR),</em> 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2304.02001" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://yzmblog.github.io/projects/MonoHuman/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> </div> </div> </li> </ol> <h2 class="year">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4"> <figure> <div class="video-container"> <video class="img-fluid z-dept-1 rounded" autoplay="" loop="" muted="" poster="/assets/img/publication/wei2022gnr.png" preload="metadata" playsinline="" webkit-playsinline="" onmouseover="this.controls=true" onmouseout="this.controls=false"><source src="/assets/videos/wei2022gnr.mp4" type="video/mp4"></source><p>Your browser does not support the video tag. <a href="/assets/videos/wei2022gnr.mp4">Download the video</a> instead.</p> </video> </div> </figure> <style>.video-container{position:relative;width:100%;height:0;padding-bottom:56.25%;background-color:#f8f9fa;border-radius:8px;overflow:hidden}.video-container video{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:8px;background-color:#000}.video-container video::-webkit-media-controls{background-color:rgba(0,0,0,0.5)}.video-container video::-webkit-media-controls-panel{background-color:transparent}.video-container video::-webkit-media-controls-play-button{background-color:transparent}.video-container video::-webkit-media-controls-timeline{background-color:transparent}.video-container video{background-color:#000!important;background-image:none!important;object-fit:cover;-webkit-appearance:none;appearance:none}.video-container video::-webkit-media-controls{background-color:transparent!important}.video-container video::-webkit-media-controls-panel{background-color:transparent!important}.video-container video::-webkit-media-controls-overlay-play-button{background-color:transparent!important}.video-container video::-webkit-media-controls-start-playback-button{background-color:transparent!important}.video-container video::-webkit-media-controls-enclosure{background-color:transparent!important}.video-container video::-webkit-media-controls-fullscreen-button{background-color:transparent!important}.video-container video::-webkit-media-controls-timeline{background-color:transparent!important}.video-container video::-webkit-media-controls-volume-slider{background-color:transparent!important}.video-container video::-webkit-media-controls-mute-button{background-color:transparent!important}.video-container video[poster]{background-color:#000!important;background-image:none!important}.video-container video::-webkit-media-controls-container{background-color:transparent!important}</style> <script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll(".video-container video").forEach(function(e){e.style.backgroundColor="#000",e.style.backgroundImage="none",e.style.webkitAppearance="none",e.style.appearance="none",e.poster&&(e.style.backgroundImage="url("+e.poster+")",e.style.backgroundSize="cover",e.style.backgroundPosition="center");["loadstart","loadedmetadata","loadeddata","canplay","canplaythrough","progress"].forEach(function(t){e.addEventListener(t,function(){this.style.backgroundColor="#000",this.style.backgroundImage=this.poster?"url("+this.poster+")":"none"})}),e.addEventListener("click",function(){this.style.backgroundColor="#000"}),e.addEventListener("mouseenter",function(){this.style.backgroundColor="#000"});new MutationObserver(function(t){t.forEach(function(t){"attributes"===t.type&&"style"===t.attributeName&&(e.style.backgroundColor="#000",e.style.backgroundImage=e.poster?"url("+e.poster+")":"none")})}).observe(e,{attributes:!0,attributeFilter:["style"]})})});</script> </div> <div id="wei2022gnr" class="col-sm-8"> <div class="title">Generalizable Neural Performer: Learning Robust Radiance Fields for Human Novel View Synthesis</div> <div class="author">Wei Cheng, Su Xu, Jingtan Piao, Chen Qian, Wayne Wu,  <em>Kwan-Yee Lin</em> †, and Hongsheng Li </div> <div class="periodical"> <em>Technical report, arXiv:2204.11798,</em> 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2204.11798" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://www.youtube.com/watch?v=2COR4u1ZIuk" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">YouTube</a> <a href="https://generalizable-neural-performer.github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <div class="video-container"> <video class="img-fluid z-dept-1 rounded" autoplay="" loop="" muted="" poster="/assets/img/publication/jianglin2022styleganhuman.png" preload="metadata" playsinline="" webkit-playsinline="" onmouseover="this.controls=true" onmouseout="this.controls=false"><source src="/assets/videos/jianglin2022styleganhuman.mp4" type="video/mp4"></source><p>Your browser does not support the video tag. <a href="/assets/videos/jianglin2022styleganhuman.mp4">Download the video</a> instead.</p> </video> </div> </figure> <style>.video-container{position:relative;width:100%;height:0;padding-bottom:56.25%;background-color:#f8f9fa;border-radius:8px;overflow:hidden}.video-container video{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:8px;background-color:#000}.video-container video::-webkit-media-controls{background-color:rgba(0,0,0,0.5)}.video-container video::-webkit-media-controls-panel{background-color:transparent}.video-container video::-webkit-media-controls-play-button{background-color:transparent}.video-container video::-webkit-media-controls-timeline{background-color:transparent}.video-container video{background-color:#000!important;background-image:none!important;object-fit:cover;-webkit-appearance:none;appearance:none}.video-container video::-webkit-media-controls{background-color:transparent!important}.video-container video::-webkit-media-controls-panel{background-color:transparent!important}.video-container video::-webkit-media-controls-overlay-play-button{background-color:transparent!important}.video-container video::-webkit-media-controls-start-playback-button{background-color:transparent!important}.video-container video::-webkit-media-controls-enclosure{background-color:transparent!important}.video-container video::-webkit-media-controls-fullscreen-button{background-color:transparent!important}.video-container video::-webkit-media-controls-timeline{background-color:transparent!important}.video-container video::-webkit-media-controls-volume-slider{background-color:transparent!important}.video-container video::-webkit-media-controls-mute-button{background-color:transparent!important}.video-container video[poster]{background-color:#000!important;background-image:none!important}.video-container video::-webkit-media-controls-container{background-color:transparent!important}</style> <script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll(".video-container video").forEach(function(e){e.style.backgroundColor="#000",e.style.backgroundImage="none",e.style.webkitAppearance="none",e.style.appearance="none",e.poster&&(e.style.backgroundImage="url("+e.poster+")",e.style.backgroundSize="cover",e.style.backgroundPosition="center");["loadstart","loadedmetadata","loadeddata","canplay","canplaythrough","progress"].forEach(function(t){e.addEventListener(t,function(){this.style.backgroundColor="#000",this.style.backgroundImage=this.poster?"url("+this.poster+")":"none"})}),e.addEventListener("click",function(){this.style.backgroundColor="#000"}),e.addEventListener("mouseenter",function(){this.style.backgroundColor="#000"});new MutationObserver(function(t){t.forEach(function(t){"attributes"===t.type&&"style"===t.attributeName&&(e.style.backgroundColor="#000",e.style.backgroundImage=e.poster?"url("+e.poster+")":"none")})}).observe(e,{attributes:!0,attributeFilter:["style"]})})});</script> </div> <div id="jianglin2022styleganhuman" class="col-sm-8"> <div class="title">StyleGAN-Human: A Data-Centric Odyssey of Human Generation</div> <div class="author">Jianglin Fu, Shikai Li, Yuming Jiang,  <em>Kwan-Yee Lin</em>, Chen Qian, Chen Change Loy, Wayne Wu, and Ziwei Liu </div> <div class="periodical"> <em>European Conference on Computer Vision (ECCV),</em> 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2205.15996" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://www.youtube.com/watch?v=nIrb9hwsdcI" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">YouTube</a> <a href="https://stylegan-human.github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/publication/upcyjc2022-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/publication/upcyjc2022-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/publication/upcyjc2022-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/publication/upcyjc2022.png"> </picture> </figure> </div> <div id="upcyjc2022" class="col-sm-8"> <div class="title">Learning a Structured Latent Space for Unsupervised Point Cloud Completion</div> <div class="author">Yingjie Cai,  <em>Kwan-Yee Lin</em> †, Chao Zhang, Qiang Wang, Xiaogang Wang, and Hongsheng Li </div> <div class="periodical"> <em>Conference on Computer Vision and Pattern Recognition (CVPR),</em> 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2203.15580" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> </div> <div class="oral-label" style="margin-top: 8px; text-align: left;"> <strong style="color: red; font-size: 1.1em;">Oral</strong> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/publication/rnnposeyx2022-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/publication/rnnposeyx2022-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/publication/rnnposeyx2022-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/publication/rnnposeyx2022.png"> </picture> </figure> </div> <div id="rnnposeyx2022" class="col-sm-8"> <div class="title">RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust Correspondence Field Estimation and Pose Optimization</div> <div class="author">Yan Xu,  <em>Kwan-Yee Lin</em> †, Guofeng Zhang, Xiaogang Wang, and Hongsheng Li </div> <div class="periodical"> <em>Conference on Computer Vision and Pattern Recognition (CVPR),</em> 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2203.12870" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://github.com/DecaYale/RNNPose" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> </div> </div> </li> </ol> <h2 class="year">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/publication/garjtp2021-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/publication/garjtp2021-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/publication/garjtp2021-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/publication/garjtp2021.png"> </picture> </figure> </div> <div id="garjtp2021" class="col-sm-8"> <div class="title">Inverting Generative Adversarial Renderer for Face Reconstruction</div> <div class="author">Jingtan Piao, Keqiang Sun, Quan Wang,  <em>Kwan-Yee Lin</em> †, and Hongsheng Li </div> <div class="periodical"> <em>Conference on Computer Vision and Pattern Recognition (CVPR),</em> 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2105.02431" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://www.youtube.com/watch?v=BzdnGMG6-cM" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">YouTube</a> <a href="https://github.com/WestlyPark/StyleRenderer" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> <div class="oral-label" style="margin-top: 8px; text-align: left;"> <strong style="color: red; font-size: 1.1em;">Oral</strong> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <div class="video-container"> <video class="img-fluid z-dept-1 rounded" autoplay="" loop="" muted="" poster="/assets/img/publication/sscyjc2021.png" preload="metadata" playsinline="" webkit-playsinline="" onmouseover="this.controls=true" onmouseout="this.controls=false"><source src="/assets/videos/sscyjc2021.mp4" type="video/mp4"></source><p>Your browser does not support the video tag. <a href="/assets/videos/sscyjc2021.mp4">Download the video</a> instead.</p> </video> </div> </figure> <style>.video-container{position:relative;width:100%;height:0;padding-bottom:56.25%;background-color:#f8f9fa;border-radius:8px;overflow:hidden}.video-container video{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:8px;background-color:#000}.video-container video::-webkit-media-controls{background-color:rgba(0,0,0,0.5)}.video-container video::-webkit-media-controls-panel{background-color:transparent}.video-container video::-webkit-media-controls-play-button{background-color:transparent}.video-container video::-webkit-media-controls-timeline{background-color:transparent}.video-container video{background-color:#000!important;background-image:none!important;object-fit:cover;-webkit-appearance:none;appearance:none}.video-container video::-webkit-media-controls{background-color:transparent!important}.video-container video::-webkit-media-controls-panel{background-color:transparent!important}.video-container video::-webkit-media-controls-overlay-play-button{background-color:transparent!important}.video-container video::-webkit-media-controls-start-playback-button{background-color:transparent!important}.video-container video::-webkit-media-controls-enclosure{background-color:transparent!important}.video-container video::-webkit-media-controls-fullscreen-button{background-color:transparent!important}.video-container video::-webkit-media-controls-timeline{background-color:transparent!important}.video-container video::-webkit-media-controls-volume-slider{background-color:transparent!important}.video-container video::-webkit-media-controls-mute-button{background-color:transparent!important}.video-container video[poster]{background-color:#000!important;background-image:none!important}.video-container video::-webkit-media-controls-container{background-color:transparent!important}</style> <script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll(".video-container video").forEach(function(e){e.style.backgroundColor="#000",e.style.backgroundImage="none",e.style.webkitAppearance="none",e.style.appearance="none",e.poster&&(e.style.backgroundImage="url("+e.poster+")",e.style.backgroundSize="cover",e.style.backgroundPosition="center");["loadstart","loadedmetadata","loadeddata","canplay","canplaythrough","progress"].forEach(function(t){e.addEventListener(t,function(){this.style.backgroundColor="#000",this.style.backgroundImage=this.poster?"url("+this.poster+")":"none"})}),e.addEventListener("click",function(){this.style.backgroundColor="#000"}),e.addEventListener("mouseenter",function(){this.style.backgroundColor="#000"});new MutationObserver(function(t){t.forEach(function(t){"attributes"===t.type&&"style"===t.attributeName&&(e.style.backgroundColor="#000",e.style.backgroundImage=e.poster?"url("+e.poster+")":"none")})}).observe(e,{attributes:!0,attributeFilter:["style"]})})});</script> </div> <div id="sscyjc2021" class="col-sm-8"> <div class="title">Semantic Scene Completion via Integrating Instances and Scene in-the-Loop</div> <div class="author">Yingjie Cai, Xuesong Chen, Chao Zhang,  <em>Kwan-Yee Lin</em> †, Xiaogang Wang, and Hongsheng Li </div> <div class="periodical"> <em>Conference on Computer Vision and Pattern Recognition (CVPR),</em> 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2104.03640" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://github.com/yjcaimeow/SISNet" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> </div> </div> </li> </ol> <h2 class="year">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/publication/sloyx2020-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/publication/sloyx2020-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/publication/sloyx2020-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/publication/sloyx2020.png"> </picture> </figure> </div> <div id="sloyx2020" class="col-sm-8"> <div class="title">SelfVoxeLO: Self-supervised LiDAR Odometry with Voxel-based Deep Neural Networks</div> <div class="author">Yan Xu, Zhaoyang Huang,  <em>Kwan-Yee Lin</em> †, Xinge Zhu, Jianping Shi, Guofeng Zhang, and Hongsheng Li </div> <div class="periodical"> <em>Conference on Robotic Learning (CoRL),</em> 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/2010.09343" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://www.youtube.com/watch?v=0clfuXZlYU4" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">YouTube</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/publication/sketchsscxk2020-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/publication/sketchsscxk2020-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/publication/sketchsscxk2020-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/publication/sketchsscxk2020.png"> </picture> </figure> </div> <div id="sketchsscxk2020" class="col-sm-8"> <div class="title">3D Sketch-aware Semantic Scene Completion via Semi-supervised Structure Prior</div> <div class="author">Xiaokang Chen,  <em>Kwan-Yee Lin</em>, Chen Qian, Gang Zeng, and Hongsheng Li </div> <div class="periodical"> <em>Conference on Computer Vision and Pattern Recognition (CVPR),</em> 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/2003.14052" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://github.com/charlesCXK/TorchSSC" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/publication/sagcxk2020-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/publication/sagcxk2020-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/publication/sagcxk2020-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/publication/sagcxk2020.png"> </picture> </figure> </div> <div id="sagcxk2020" class="col-sm-8"> <div class="title">Bi-directional Cross-Modality Feature Propagation with Separation-and-Aggregation Gate for RGB-D Semantic Segmentation</div> <div class="author">Xiaokang Chen,  <em>Kwan-Yee Lin</em>, Jingbo Wang, Wayne Wu, Chen Qian, Hongsheng Li, and Gang Zeng </div> <div class="periodical"> <em>The European Conference on Computer Vision (ECCV),</em> 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/2007.09183" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://github.com/charlesCXK/RGBD_Semantic_Segmentation_PyTorch" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> </div> </div> </li> </ol> <h2 class="year">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/publication/trbhdd2019-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/publication/trbhdd2019-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/publication/trbhdd2019-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/publication/trbhdd2019.png"> </picture> </figure> </div> <div id="trbhdd2019" class="col-sm-8"> <div class="title">TRB: A Novel Triplet Representation for Understanding 2D Human Body</div> <div class="author">Haodong Duan,  <em>Kwan-Yee Lin</em>, Sheng Jin, Wentao Liu, Chen Qian, and Wanli Ouyang </div> <div class="periodical"> <em>International Conference on Computer Vision (ICCV),</em> 2019 </div> <div class="links"> <a href="http://arxiv.org/abs/1910.11535" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://github.com/kennymckormick/Triplet-Representation-of-human-Body" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Project Page</a> </div> <div class="oral-label" style="margin-top: 8px; text-align: left;"> <strong style="color: red; font-size: 1.1em;">Oral</strong> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/publication/mafsjq2019-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/publication/mafsjq2019-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/publication/mafsjq2019-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/publication/mafsjq2019.png"> </picture> </figure> </div> <div id="mafsjq2019" class="col-sm-8"> <div class="title">Make a Face: Towards Arbitrary High Fidelity Face Manipulation</div> <div class="author">Shengju Qian,  <em>Kwan-Yee Lin</em>, Wayne Wu, Quan Wang, Ran He, Fumin Shen, and Chen Qian </div> <div class="periodical"> <em>International Conference on Computer Vision (ICCV),</em> 2019 </div> <div class="links"> <a href="http://arxiv.org/abs/1908.07191" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <div class="video-container"> <video class="img-fluid z-dept-1 rounded" autoplay="" loop="" muted="" poster="/assets/img/publication/3dhumanposekylin2019.png" preload="metadata" playsinline="" webkit-playsinline="" onmouseover="this.controls=true" onmouseout="this.controls=false"><source src="/assets/videos/3dhumanposekylin2019.mp4" type="video/mp4"></source><p>Your browser does not support the video tag. <a href="/assets/videos/3dhumanposekylin2019.mp4">Download the video</a> instead.</p> </video> </div> </figure> <style>.video-container{position:relative;width:100%;height:0;padding-bottom:56.25%;background-color:#f8f9fa;border-radius:8px;overflow:hidden}.video-container video{position:absolute;top:0;left:0;width:100%;height:100%;border-radius:8px;background-color:#000}.video-container video::-webkit-media-controls{background-color:rgba(0,0,0,0.5)}.video-container video::-webkit-media-controls-panel{background-color:transparent}.video-container video::-webkit-media-controls-play-button{background-color:transparent}.video-container video::-webkit-media-controls-timeline{background-color:transparent}.video-container video{background-color:#000!important;background-image:none!important;object-fit:cover;-webkit-appearance:none;appearance:none}.video-container video::-webkit-media-controls{background-color:transparent!important}.video-container video::-webkit-media-controls-panel{background-color:transparent!important}.video-container video::-webkit-media-controls-overlay-play-button{background-color:transparent!important}.video-container video::-webkit-media-controls-start-playback-button{background-color:transparent!important}.video-container video::-webkit-media-controls-enclosure{background-color:transparent!important}.video-container video::-webkit-media-controls-fullscreen-button{background-color:transparent!important}.video-container video::-webkit-media-controls-timeline{background-color:transparent!important}.video-container video::-webkit-media-controls-volume-slider{background-color:transparent!important}.video-container video::-webkit-media-controls-mute-button{background-color:transparent!important}.video-container video[poster]{background-color:#000!important;background-image:none!important}.video-container video::-webkit-media-controls-container{background-color:transparent!important}</style> <script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll(".video-container video").forEach(function(e){e.style.backgroundColor="#000",e.style.backgroundImage="none",e.style.webkitAppearance="none",e.style.appearance="none",e.poster&&(e.style.backgroundImage="url("+e.poster+")",e.style.backgroundSize="cover",e.style.backgroundPosition="center");["loadstart","loadedmetadata","loadeddata","canplay","canplaythrough","progress"].forEach(function(t){e.addEventListener(t,function(){this.style.backgroundColor="#000",this.style.backgroundImage=this.poster?"url("+this.poster+")":"none"})}),e.addEventListener("click",function(){this.style.backgroundColor="#000"}),e.addEventListener("mouseenter",function(){this.style.backgroundColor="#000"});new MutationObserver(function(t){t.forEach(function(t){"attributes"===t.type&&"style"===t.attributeName&&(e.style.backgroundColor="#000",e.style.backgroundImage=e.poster?"url("+e.poster+")":"none")})}).observe(e,{attributes:!0,attributeFilter:["style"]})})});</script> </div> <div id="3dhumanposekylin2019" class="col-sm-8"> <div class="title">Weakly-Supervised Discovery of Geometry-Aware Representation for 3D Human Pose Estimation</div> <div class="author"> <em>Kwan-Yee Lin</em>, Xipeng Chen, Wentao Liu, Chen Qian, and Liang Lin </div> <div class="periodical"> <em>Conference on Computer Vision and Pattern Recognition (CVPR),</em> 2019 </div> <div class="links"> <a href="http://arxiv.org/abs/1903.08839" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://kwanyeelin.github.io/projects/GeoRep-3DPose/GeoRep-3DPose.html" class="btn btn-sm z-depth-0" role="button">Project Page</a> </div> <div class="oral-label" style="margin-top: 8px; text-align: left;"> <strong style="color: red; font-size: 1.1em;">Oral</strong> </div> </div> </div> </li> </ol> <h2 class="year">2018</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/publication/hallucinatediqakylin2019-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/publication/hallucinatediqakylin2019-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/publication/hallucinatediqakylin2019-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/publication/hallucinatediqakylin2019.png"> </picture> </figure> </div> <div id="hallucinatediqakylin2019" class="col-sm-8"> <div class="title">Hallucinated-IQA: No-reference Image Quality Assessment via Adversarial Learning</div> <div class="author"> <em>Kwan-Yee Lin</em>, and Guanxiang Wang </div> <div class="periodical"> <em>Conference on Computer Vision and Pattern Recognition (CVPR),</em> 2018 </div> <div class="links"> <a href="http://arxiv.org/abs/1804.01681" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a href="https://kwanyeelin.github.io/projects/HIQA/HIQA.html" class="btn btn-sm z-depth-0" role="button">Project Page</a> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Kwan-Yee Lin. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Last updated: September 08, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script src="/assets/js/zoom.js"></script> <script src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-4QS9LCB68Y"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-4QS9LCB68Y");</script> </body> </html>